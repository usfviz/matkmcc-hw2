lm_block <- lm(data = dat, formula = Y ~ I(X1*block) + X2 + block)
dat <- cakes
dat$block <- as.numeric(dat$block)
lm_block <- lm(data = dat, formula = Y ~ I(X1*block) + X2 + block)
summary(lm_block)
residualPlots(lm_block)
lm_block <- lm(data = dat, formula = Y ~ I(X1*block) + X2 + X2^2 + block)
summary(lm_block)
residualPlots(lm_block)
lm_block <- lm(data = dat, formula = Y ~ X1^2 + X2 + X2^2 + block)
summary(lm_block)
residualPlots(lm_block)
scatterplot.matrix(dat)
dat
lm_dat_3 <- lm(data = dat, formula = Y ~ X1 + X2 + X2^2 + I(X1*X2) + I(X1*X2)^2 )
summary(lm_dat_3)
residualPlots(lm_dat_3)
lm_dat <- lm(data = dat, formula = Y ~ X1 + X2)
summary(lm_dat)
residualPlots(lm_dat)
lm_dat_2 <- lm(data = dat, formula = Y ~ X1 + X2 + I(X1*X2))
summary(lm_dat_2)
residualPlots(lm_dat_2)
lm_dat <- lm(data = dat, formula = Y ~ X1 + X2)
summary(lm_dat)
residualPlots(lm_dat)
lm_dat_3 <- lm(data = dat, formula = Y ~ X1 + X2 + X2^2 + I(X1*X2) + I(X1*X2)^2 )
summary(lm_dat_3)
residualPlots(lm_dat_3)
reset_dat <- resettest(lm_dat, power = 2:3)
library(lmtest)
reset_dat <- resettest(lm_dat, power = 2:3)
reset_dat
reset_dat <- resettest(lm_dat, power = 2)
reset_dat
lm_dat <- lm(data = dat, formula = Y ~ X1 + X2)
lm_dat_2 <- lm(data = dat, formula = Y ~ X1 + X2 + I(X1*X2))
lm_dat <- lm(data = dat, formula = Y ~ X1 + X2)
sum_dat <- summary(lm_dat)
sum_dat
lm_dat_3 <- lm(data = dat, formula = Y ~ X1 + X2 + X2^2 + I(X1*X2) + I(X1*X2)^2 )
summary(lm_dat_3)
residualPlots(lm_dat_3)
lm_dat <- lm(data = dat, formula = Y ~ X1 + X2)
summary(lm_dat)
residualPlots(lm_dat)
lm_dat_3 <- lm(data = dat, formula = Y ~ X1 + X2 + X2^2 + I(X1*X2) + I(X1*X2)^2 )
summary(lm_dat_3)
residualPlots(lm_dat_3)
getwd()
speed = distance / air_time * 60)
mutate(flights,
gain = arr_delay - dep_delay,
speed = distance / air_time * 60)
# What is dplyr?
# - Stackoverflow
# -- 3 Major Goals
# --- 1. Identify the most important data manipulation tools needed for data
# --- analysis and make them easy to use from R
# --- 2. Provide 'blazing' fast performance for in-memory data with C++
# --- 3. Use the same interface to work with data no matter where it is stored
# --- (dataframe, data table, or database)
# --- Translates commands to SQL for remote databases
# Excersizes : nycflights13 - https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html
install.packages('nycflights13')
# What is dplyr?
# - Stackoverflow
# -- 3 Major Goals
# --- 1. Identify the most important data manipulation tools needed for data
# --- analysis and make them easy to use from R
# --- 2. Provide 'blazing' fast performance for in-memory data with C++
# --- 3. Use the same interface to work with data no matter where it is stored
# --- (dataframe, data table, or database)
# --- Translates commands to SQL for remote databases
# Excersizes : nycflights13 - https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html
#install.packages('nycflights13')
library(nycflights13)
library(dplyr)
dim(flights)
head(flights)
str(flights)
# dplyr functions -
# --filter(), slice()
# --arrange()
# --select(), rename()
# --distinct()
# --mutate(), transmute()
# --summarise()
# --sample_n(), sample_frac()
####### ---- EXAMNINE - filter()
# select all flights on Januare 1st - First argument is the DF, subsequent arguments are filter by:
# ---- Note that splitting dates by idividual integer components may be a useful opertion
filter(flights, month == 1, day == 1)
# this dplyr function is equal to:
flights[flights$month == 1 & flights$day == 1, ]
# wonder if one is faster than the other - difference seems negligable and this data set is large
subset(flights, month == 1 & day == 1 | arr_delay == 11)
filter(flights, month == 1 & day == 1 | arr_delay == 11) # seems equivelant
####### ---- EXAMNINE - slice()
slice(flights, 1:10) # indexing method - wonder why they felt the need to use this?
####### ---- EXAMNINE - arrange()
# Reorders rows of a dataframe and column names
# - Arguments: Takes data frame and then subsequent columns to order by
arrange(flights, year, month, day)
# desc() to order in descending order (default is ascending)
arrange(flights, year, desc(month), day)
# descendent from the order function -
flights[order(flights$year, flights$month, flights$day), ]
flights[order(flights$arr_delay, decreasing = TRUE), ]
flights[order(flights$year, -flights$month, flights$day), ]
####### ---- EXAMNINE - select()
# Enables subsetting by column
# - Works similiarly to above - Dataframe then column arguments
select(flights, year, month, day)
select (flights, year:day) # select all columns between the given columns
select (flights, -(year:day)) # select all columns except the negated ones
# also derivitive of subset
subset(flights, select = - c(year, month, day)) # Similiar to subset - but dplyr mantra decrees
subset(flights, select = c(year:day)) # that it will use simple bite-sized functions that do one
subset(flights, select = c(year, month, day)) # thing well
select(flights, tail_num = tailnum) # allows you to rename a selected column - but still subetting
####### ---- EXAMNINE - rename()
# Allows you to rename a column without subsetting
str(rename(flights, tail_num = tailnum))
####### ---- EXAMNINE - distinct()
# distinct works similiarly to unique - but reformatted to dplyr syntax
# - should be faster than unique()
distinct(flights, tailnum)
arrange(distinct(flights, origin, dest), origin, dest) # finds unique value pairs
unique(flights$tailnum)
# unique(flights$origin, flights$dest) # this is a time bomb -- don't know if syntax is
# correct but it crashed my comp. last time
####### ---- EXAMNINE - mutate()
mutate(flights,
gain = arr_delay - dep_delay,
speed = distance / air_time * 60)
speed = distance / air_time * 60))
####### ---- EXAMNINE - mutate()
str(mutate(flights,
gain = arr_delay - dep_delay,
speed = distance / air_time * 60))
str(mutate(flights,
gain = arr_delay - dep_dealy,
gain_per_hour = gain/arr_time * 60))
str(mutate(flights,
gain = arr_delay - dep_delay,
gain_per_hour = gain/arr_time * 60))
str(mutate(flights,
gain = arr_delay - dep_delay,
gain_per_hour = gain/(arr_time / 60)))
str(mutate(flights,
gain = arr_delay - dep_delay,
gain_per_hour = gain/arr_time * 60))
transform(flights,
gain = arr_delay - delay,
gain_per_hour = gain / air_time * 60)
transform(flights,
gain = arr_delay - dep_delay,
gain_per_hour = gain / air_time * 60)
gain = arr_delay - dep_delay)
transform(flights,
gain = arr_delay - dep_delay)
summarise(flights,
delay = mean(dep_delay, na.rm = TRUE))
sample_n(flights, 10)
sample_frac(flights, 0.01)
?sample_n
by_tailnum <- group_by(flight, tailnum)
by_tailnum <- group_by(flights, tailnum)
by_tailnum <- group_by(flights, tailnum) # similiar structure again (df, tailnum)
delay <- summarise(by_tailnum,
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dist > 2000)
library(ggplot2)
by_tailnum <- group_by(flights, tailnum) # similiar structure again (df, tailnum)
delay <- summarise(by_tailnum,
count = n(), # number of instances
dist = mean(distance, na.rm = TRUE), # mean of distance travelled
delay = mean(arr_delay, na.rm = TRUE)) # mean arrival_delay
delay <- filter(delay, count > 20, dist > 2000)
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_plot(aes(size = count), alpha = 1/2.0) +
geom_smooth() +
scale_size_area()
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2.0) +
geom_smooth() +
scale_size_area()
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area()
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area()
delay <- filter(delay, count > 20, dist > 2000)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area()
by_tailnum <- group_by(flights, tailnum) # similiar structure again (df, tailnum)
delay <- summarise(by_tailnum,
count = n(), # number of instances
dist = mean(distance, na.rm = TRUE), # mean of distance travelled
delay = mean(arr_delay, na.rm = TRUE)) # mean arrival_delay
delay <- filter(delay, count > 20, dist < 2000)
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area()
destinations <- group_by(flights, dest)
summarise(destinations, planes = n_distinct(tainnum),
flights = n())
)
summarise(destinations, planes = n_distinct(tainnum),
flights = n())
summarise(destinations, planes = n_distinct(tailnum),
flights = n())
daily <- group_by(flights, year, month, day)
(per_day <- summarise(daily, flights = n()))
(per_month <- summarise(per_day, flights = sum(flights)))
(per_year <- summarise(per_month, flights = sum(flights)))
daily <- group_by(flights, year, month, day) # progressive rolling up of summaries
per_day <- summarise(daily, flights = n()) # what is the purpose of the parenthesis?
per_month <- summarise(per_day, flights = sum(flights))
per_year <- summarise(per_month, flights = sum(flights))
a1 <- group_by(flights, year, month, day)
a2 <- select(a1, arr_delay, dep_delay)
a3 <- summarise(a2,
arr = mean(arr_delay, na.rm = TRUE),
dep = mean(dep_delay, na.rm = TRUE))
a4 <- filter(a3, arr > 30 | dep > 30 )
a4
(a4 <- filter(a3, arr > 30 | dep > 30 ))
a1 <- group_by(flights, year, month, day)
a2 <- select(a1, arr_delay, dep_delay)
a3 <- summarise(a2,
arr = mean(arr_delay, na.rm = TRUE),
dep = mean(dep_delay, na.rm = TRUE))
(a4 <- filter(a3, arr > 30 | dep > 30 ))
filter(
summarise(
select(
group_by(flights, year, month, day),
arr_delay, dep_delay
),
arr = mean(arr_delay, na.rm = TRUE),
dep = mean(dep_delay, na.rm = TRUE)
),
arr > 30 | dep > 30
)
flights %>%
group_by(year, month, day) %>%
select(arr_delay, dep_delay) %>%
summarise(
arr = mean(arr_delay, na.rm = TRUE),
dep = mean(dep_delay, na.rm = TRUE)
) %>%
filter(arr > 30 | dep > 30)
flights %>%
group_by(year, month, day) %>%
select(arr_delay, dep_delay) %>%
summarise(
arr = mean(arr_delay, na.rm = TRUE),
dep = mean(dep_delay, na.rm = TRUE)
) %>%
filter(arr > 30 | dep > 30)
library(x12)
x12(AirPassengers)
x13path(/usr/local/bin/x13as/x13asall_V1.1_B26/x13as')
x13path('usr/local/bin/x13as/x13asall_V1.1_B26/x13as')
x13path('usr/local/bin/x13as/x13asall_V1.1_B26/x13a')
x13path('usr/local/bin/x13as/x13asall_V1.1_B26/x13')
x13path('/usr/local/bin/x13as/x13asall_V1.1_B26/x13as')
x12(AirPassengers)
cat('\014')
library(x12)
x12(AirPassengers)
x13('/usr/local/bin/x13as/x13asall_V1.1_B26/x13as')
x13path('/usr/local/bin/x13as/x13asall_V1.1_B26/x13as')
x12(AirPassengers)
install.packages('VARS')
install.packages('VARs')
cat('/014')
cat('\014')
data(cats, package = 'MASS')
linmodEst <- function(x,y)
{
## compute QR-decomposition of x
qx <- qr(x)
## compute (x'x) ^ (-1) x'y
coef <- solve.qr(qx, y)
## degrees of freedom and standard deviation of residuals
df <- nrow(x)-ncol(x)
sigma2 <- sum((y - x%*%coef)^2)/df
## compute sigma^2 * (x'x)^-1
vcov <- sigma2 * chol2inv(qx$qr)
colnames(vcov) <- rownames(vcov) <- colnames(x)
list(coefficients = coef,
vcov = vcov,
sigma = sqrt(sigma2),
df = df)
}
linmodEst(cbind(1, cats$Bwt), cats$Hwt)
cats$Bwt
cbind(cats$Bwt)
cbind(1, cats$Bwt)
cats$Hwt
?qr()
x <- cbind(1, cats$Bwt)
x
qx  <- qr(x)
coef  <- solve.qr(qx, y)
y <- cats$Hwt
coef  <- solve.qr(qx, y)
df  <- nrow(x) - ncol(x)
sum((y - x * coef)^2)/df
sum((y - x%*%coef)^2)/df
}
x%*%ceof
x%*%coef
x*coef
coef
shape(coef)
dim(coef)
linmodEst(cbind(1, cats$Bwt), cats$Hwt)
lm(formula = cats$Hwt ~ cats$Bwt)
lm(formula = cats$Hwt ~ cbind(1, cats$Bwt))
lm(formula = cats$Hwt ~ cats$Bwt)
linmodEst(cbind(1, cats$Bwt), cats$Hwt)
x <- rep(0:1, c(10,20))
x
class(x)
summary(x)
y  <- as.factor(x)
class(y)
summary(y)
attributes(y)
myx <- x
class(myx)
class(myx)  <- 'myvector'
class(myx)
summary.integer(x)
summary.integer()
summary.numeric(x)
summary.factor(y)
Summary.numeric_version(x)
summary.default(x)
summary.factor(x)
print.myvector  <- function(x, ...) {}
print.myvector  <- function(x, ...) {
cat('this is my vector: \n')
cat(past(x[1:5]), "...\n")}
x
myx
print.myvector  <- function(x, ...) {
cat('this is my vector: \n')
cat(pas3t(x[1:5]), "...\n")}
print.myvector  <- function(x, ...) {
cat('this is my vector: \n')
cat(paste(x[1:5]), "...\n")}
myx
library(ggmap)
distQueryCheck()
distQueryCheck()
library(ggmap)
distQueryCheck()
install.packages('leaflet')
library(leaflet)
addMarkers(lng = 174.768, lat = -35.852, popup = "The birthplace of R")
m <- leaflet() %>%
addTiles() %>% # add default OpenStreetMap map tiles
addMarkers(lng = 174.768, lat = -35.852, popup = "The birthplace of R")
m
m <- leaflet() %>%
addTiles() %>% # add default OpenStreetMap map tiles
addMarkers(lng = 174.768, lat = -36.852, popup = "The birthplace of R")
m
leaflet(options = leafletOptions(minZoom = 0, maxZoom = 18))
leaflet(df) %>% addCircles()
df = data.frame(Lat = 1:10, Long = rnorm(10))
leaflet(df) %>% addCircles()
leaflet(df) %>% addCircles(lng = ~Lat, lat = ~Long)
leaflet(df) %>% addCircles()
install.packages('sp')
Sr1 = Polygon(cbind(c(2,4,4,1,2), c(2,3,4,2)))
library(sp)
Sr1 = Polygon(cbind(c(2,4,4,1,2), c(2,3,5,4,2)))
Sr2 = Polygon(cbind(c(5,4,2,5), c(2,3,2,2)))
Sr3 = Polygon(cbind(c(4,4,5,10,4), c(5,3,2,5,5)))
Sr4 = Polygon(cbind(c(5,6,6,5,5), c(4,4,3,3,4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr4, Sr2, Sr3), 1:3)
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
Sr1 = Polygon(cbind(c(2,4,4,1,2), c(2,3,5,4,2)))
Sr2 = Polygon(cbind(c(5,4,2,5), c(2,3,2,2)))
Sr3 = Polygon(cbind(c(4,4,5,10,4), c(5,3,2,5,5)))
Sr4 = Polygon(cbind(c(5,6,6,5,5), c(4,4,3,3,4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr4, Sr2, Sr3), 1:3)
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
Srs3 = Polygons(list(Sr4, Sr2, Sr3), "s3/4")
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
leaflet(height = "300px") %>% addPolygons(data = SpP)
install.packages('rgeos')
library(sp)
leaflet(height = "300px") %>% addPolygons(data = SpP)
Sr1 = Polygon(cbind(c(2,4,4,1,2), c(2,3,5,4,2)))
Sr2 = Polygon(cbind(c(5,4,2,5), c(2,3,2,2)))
Sr3 = Polygon(cbind(c(4,4,5,10,4), c(5,3,2,5,5)))
Sr4 = Polygon(cbind(c(5,6,6,5,5), c(4,4,3,3,4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr4, Sr3), "s3/4")
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
leaflet(height = "300px") %>% addPolygons(data = SpP)
SpP
mapStates = map("state", fill = TRUE, plot = FALSE)
install.packages('map')
install.packages('maps')
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
leaflet(data = mapstates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
class(mapStates)
typeof(mapStates)
mapStates
df = data.frame(
lat = rnorm(100),
lng = rnorm(100),
size = runif(100, 5, 20),
color = sample(colors(), 100)
)
m = leaflet(df) %>% addTiles()
m %>% addCircleMarkers(radius = ~size, color = ~color, fill = FALSE)
m %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red')
m %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))
m %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))
df
m <- leaflet() %>% setView(lng = -71.0589, lat = 42.3601, zoom = 12)
m %>% addtiles
m %>% addTiles()
m <- leaflet() %>% setView(lng = -71.0589, lat = 42.3601, zoom = 12)
m
m %>% addTiles()
rm(ls = list())
rm(ls = list())
rm(list = ls())
cat('\014')
install.packages('tigris')
library(tigris)
blocks('CA', county = 037)
LA_blocks <- blocks(06, county = 037)
LA_blocks <- blocks(06, county = 037)
rm(list = ls())
cat('/014')
cat('\014')
library(shiny)
setwd('~/Desktop/MSAN622-DV/Assignment2/API_SP/')
starting <- read.csv('API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv')
starting
starting <- read.csv('API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
starting <- read.csv('Metadata_Country_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
starting
colnames(starting)
d1 <- read.csv('Metadata_Country_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
d2 <- read.csv('Metadata_Indicator_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
colnames(starting)
d1 <- read.csv('Metadata_Country_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
d2 <- read.csv('Metadata_Indicator_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
colnames(starting)
colnames(d2)
d2
head(d2)
d3 <- read.csv('API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
head(d2)
head(d3)
d3 <- read.csv('API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
head(d3)
setwd('~/Desktop/MSAN622-DV/Assignment2/API_SP-2/')
d1 <- read.csv('API_SP.DYN.TFRT.IN_DS2_en_csv_v2.csv')
d5 <- read.csv('Metadata_Country_API_SP.DYN.TFRT.IN_DS2_en_csv_v2.csv')
d6 <- read.csv('Metadata_Indicator_API_SP.DYN.TFRT.IN_DS2_en_csv_v2.csv')
d5
head(d5)
head(d6)
d4 <- read.csv('API_SP.DYN.TFRT.IN_DS2_en_csv_v2.csv')
d1 <- read.csv('Metadata_Country_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
d2 <- read.csv('Metadata_Indicator_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
d3 <- read.csv('API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
setwd('~/Desktop/MSAN622-DV/Assignment2/API_SP-2/')
d4 <- read.csv('API_SP.DYN.TFRT.IN_DS2_en_csv_v2.csv')
d5 <- read.csv('Metadata_Country_API_SP.DYN.TFRT.IN_DS2_en_csv_v2.csv')
d6 <- read.csv('Metadata_Indicator_API_SP.DYN.TFRT.IN_DS2_en_csv_v2.csv')
setwd('~/Desktop/MSAN622-DV/Assignment2/API_SP/')
d1 <- read.csv('Metadata_Country_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
d2 <- read.csv('Metadata_Indicator_API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
d3 <- read.csv('API_SP.DYN.LE00.IN_DS2_en_csv_v2.csv', stringsAsFactors = F)
colnames(d1)
head(d3)
unique(d3$Indicator.Name)
unique(d3$Indicator.Name)
